{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "629S_AcrwV-m"
      },
      "outputs": [],
      "source": [
        "## Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Ans::  OVERFITTING:: Overfitting and underfitting occur while training our machine learning or deep learning models – they are usually the common underliers of our models’ poor performance.\n",
        "        ## The Overfitting means our training has focused on the particular training set so much that it has missed the point entirely. \n",
        "        ## In this way, the model is not able to adapt to new data as it’s too focused on the training set.\n",
        "# Ex: Train Dataset: Model is Trained with High Accuracy(95%) -> LOW BIAS \n",
        "    # Test Dataset: Model is Tested with Low Accuracy(65%)  ->  HIGH VARIANCE \n",
        "\n",
        "    #### UNDERFITTING: In Underfitting the training dataset has low accuracy and the test dataset also has low accuracy\n",
        "# Ex: Train Dataset: Model is Trained with Low Accuracy(55%) -> HIGH BIAS \n",
        "    # Test Dataset: Model is Tested with Low Accuracy(50%)  ->  HIGH VARIANCE \n",
        "\n",
        "    ## GENERALIZED MODEL: In this case\n",
        "    # Ex: Train Dataset: Model is Trained with High Accuracy(85%) -> LOW BIAS \n",
        "    # Test Dataset: Model is Tested with High Accuracy(87%)  ->  LOW VARIANCE \n",
        "## NOTE: As a Data Scientist The Train and Test Data Set should be good with Low Bias and Low Vairiance.\n",
        "   "
      ],
      "metadata": {
        "id": "HGHP8150we79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2: How can we reduce overfitting? Explain in brief.\n",
        "#Ans: Overfitting is a common problem in machine learning where a model becomes too complex and starts to memorize the training data rather than learning general patterns. \n",
        " # This leads to poor performance on new data. Fortunately, there are several techniques to reduce overfitting:::\n",
        " #1. Cross-validation: Cross-validation involves splitting the data into multiple folds and training the model on different combinations of these folds. \n",
        " #2. Regularization:Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting.\n",
        " #3. Data augmentation: Data augmentation involves creating new training data by applying transformations to the existing data. This helps to increase the size of the training set and reduce overfitting.\n",
        " #4. Early stopping: Early stopping involves monitoring the validation error during training and stopping the training process when the validation error starts to increase. This helps to prevent the model from overfitting to the training data.\n",
        " #5. Simplifying the model: Sometimes, a simpler model may perform better than a complex one. This can be achieved by reducing the number of features."
      ],
      "metadata": {
        "id": "nu3sroHtywPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
        "#Ans: When the model leads to poor performance on both the training and test data. The scenarios are::\n",
        "  #1. Insifficient data:  If the amount of training data is too small, it can be difficult for the model to learn the underlying patterns in the data.\n",
        "  #2. Oversimplification of the model: If the model is too simple, it may not be able to capture the complexity of the data.\n",
        "  #3. Inappropriate feature selection: If the features selected for the model do not capture the underlying patterns in the data, the model may underfit.\n",
        "  #4. High regularization: Regularization is a technique used to prevent overfitting, but if the regularization parameter is set too high, it may lead to underfitting.\n",
        "  #5. Training for too few epochs: If the model is trained for too few epochs, it may not have had enough time to learn the underlying patterns in the data, leading to underfitting.\n",
        "  "
      ],
      "metadata": {
        "id": "jRGI6kQt3pCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n",
        "#Ans: Bias:: It is related to Performance of the model. The Bias refers to approximate the real world problem of the data.It refers to the predictions related to actual data.\n",
        "             # A High Bias leads to Underfit the data.\n",
        "   # Variance:: Variance is the error introduced by the model's sensitivity to small fluctuations in the training data. \n",
        "             # A high variance model is too complex and tends to overfit the data.\n",
        "# The difference between Bias and Variance can be illustrated by the bias-variance decomposition of the mean squared error (MSE) of a model. \n",
        " # The MSE is the expected value of the squared difference between the predicted values and the actual values of the data. \n",
        " # The bias-variance tradeoff states that as the complexity of the model increases, the bias decreases and the variance increases.\n",
        " # On the other hand, as the complexity of the model decreases, the bias increases and the variance decreases.\n",
        "\n",
        " # A model with high bias and low variance tends to underfit the data, while a model with low bias and high variance tends to overfit the data. \n",
        " #The goal is to find the right balance between bias and variance that minimizes the overall error of the model."
      ],
      "metadata": {
        "id": "KyZsH2gi5Eu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?\n",
        "#Ans: Detecting overfitting and underfitting in machine learning models is crucial for building accurate and reliable models. Here are some common methods for detecting overfitting and underfitting:\n",
        "#1. Cross Validation\n",
        "#2. Learning Curves\n",
        "#3. Regularization\n",
        "#4. Complexity\n",
        "#5. Visual Inspection\n"
      ],
      "metadata": {
        "id": "JBh12eQQ7dmv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}